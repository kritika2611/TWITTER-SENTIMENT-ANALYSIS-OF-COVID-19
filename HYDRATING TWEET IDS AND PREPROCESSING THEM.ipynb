{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERTING CSV FILES INTO TXT FOR INPUT TO TWARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the file you want to process: corona_tweets_02\n"
     ]
    }
   ],
   "source": [
    "file_=str(input(\"Enter the name of the file you want to process: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IEEE dataset/ORIGINAL DATA/'+file_+'.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240862157228703744</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240862157266272257</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240862157924859904</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240862157992079360</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240862158130253825</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1\n",
       "0  1240862157228703744  0.366667\n",
       "1  1240862157266272257  0.025000\n",
       "2  1240862157924859904 -0.166667\n",
       "3  1240862157992079360 -0.333333\n",
       "4  1240862158130253825  0.200000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(870924, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids=[int(i) for i in data[:,0]]\n",
    "ids=np.asarray(ids)\n",
    "sent_score=np.asarray(data[:,1])\n",
    "df=list(zip(ids,sent_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1240862157228703744, 0.3666666666666667),\n",
       " (1240862157266272256, 0.024999999999999998),\n",
       " (1240862157924859904, -0.16666666666666666),\n",
       " (1240862157992079360, -0.3333333333333333),\n",
       " (1240862158130253824, 0.2),\n",
       " (1240862158466023424, 0.3666666666666667),\n",
       " (1240862158646210560, -0.3125),\n",
       " (1240862158847705088, 0.5),\n",
       " (1240862158721675264, 0.0),\n",
       " (1240862158822477824, 0.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dict([key,value] for (key,value) in df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file=open('IEEE dataset/TWEET IDS/'+file_+'.txt','w',encoding='utf8')\n",
    "for i in ids:\n",
    "    print((i),file=out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY PREPROCESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LowerCasing- The tweet is first converted into lower case\n",
    "* Removal of Retweet|RT|via\n",
    "* Removal of mentions(like @xyz)\n",
    "* Removal of links in the tweet\n",
    "* Negation handling\n",
    "* Tokenisation to get standard english words only\n",
    "* Stop word removal - the stopwords were modified\n",
    "* Lemmatization using WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=RegexpTokenizer(r'[a-zA-Z]+')     #taking only alphabets\n",
    "sw=stopwords.words(\"english\")\n",
    "lm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.remove('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations=[\"isn't\",\"aren't\",\"wasn't\",\"weren't\",\"won't\", \"wouldn't\",\"ain't\",\"doesn't\",\"don't\",\"didn't\", \"can't\",\"couldn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \"mightn't\", \"mustn't\", \"needn't\", \"shan't\", \"shouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data(text):\n",
    "    text=text.lower()\n",
    "    #removing retweets\n",
    "    text=re.sub(r'(rt|RT|retweet|from|via)',\"\",text)\n",
    "    \n",
    "    #removing mentions \n",
    "    mentions=re.findall(\"@[A-Za-z0-9_]+\",text)\n",
    "    for m in mentions:\n",
    "        text=text.replace(m,\"\")\n",
    "        \n",
    "    #links removal\n",
    "    urls=re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    for u in urls:\n",
    "        text=text.replace(u,\"\")\n",
    "        \n",
    "    #handling negations- REPLACING ALL THE NEGATIVE HELPING VERBS WITH NOT\n",
    "    for w in negations:\n",
    "        if text.find(w)!=-1:\n",
    "            text=text.replace(w,'not')\n",
    "            \n",
    "    #tokenisation\n",
    "    tokens=tok.tokenize(text)      #takes only standard english alphabets\n",
    "    #stopword removal\n",
    "    new_tokens=[t for t in tokens if t not in sw and len(t)>2]\n",
    "    #stemming\n",
    "    clean_text=[lm.lemmatize(t) for t in new_tokens]\n",
    "    \n",
    "    clean_text=\" \".join(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not worry pandemic end soon wash hand regular itervals not step outside without wearing mask seeing following symptom dry cough high fever breathing difficulty loss taste loss smell visit nearby hospital detail visit indiafightscorona'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_data(\"\"\"RT@abc, @ghs: Don't worry, this pandemic will end soon\n",
    "Wash your hands at regular itervals, Do not a step outside without wearing a mask :)\n",
    "On seeing any of the following symptoms: dry cough, high fever, breathing difficulty, loss of taste, loss of smell, visit nearby hospital\n",
    "For more details visit:'http://tnp.dtu.ac.in/rm_2016-17/intern/intern_login,\n",
    " 'https://icmr.gov.in',\n",
    " 'http://www.google.com/egfbhsd/g\n",
    "#IndiafightsCorona\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'message universal stay home stay safe let defeat corona together day rediscovered farming ceo find nearby corona testing treatment amp isolation close president note seen crossed corona replaced chinese virus corona virus got texting people back lol corona day feel like sunday house intimidate corona deleted scene twd special corona virus captain never change'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_data(\"\"\"RT @ashokgehlot51: This message is universal . Stay home, stay safe - let’s Defeat Corona together #राजस्थान_सतर्क_है\n",
    "RT @MakedaMorrison: Day 5: We have rediscovered farming\n",
    "RT @_rohanverma: I am the CEO of @MapmyIndia - through https://t.co/p8Iqtoz77t all can find nearby corona testing, treatment &amp; isolation ce…\n",
    "RT @jabinbotsford: Close up of President @realDonaldTrump notes is seen where he crossed out \"Corona\" and replaced it with \"Chinese\" Virus…\n",
    "This corona virus got me texting people back now lol.\n",
    "RT @Biancaixvi: Corona day 3: it just feels like Sunday again and...again\n",
    "house. he will intimidate the corona https://t.co/KXrYmAS25H\n",
    "RT @chandlerriggs: here’s a deleted scene from TWD’s special on corona virus https://t.co/qGuSfyjpK5\n",
    "RT @suliceu99: our captain never change :\") https://t.co/47gGJdiIvs\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYDRATING IDS USING TWARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twarc import Twarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_credentials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Twarc(CONSUMER_KEY,CONSUMER_SECRET,ACCESS_TOKEN,ACESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twarc.client.Twarc"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:twarc:rate limit exceeded: sleeping 177.41943073272705 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 191.56946969032288 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 183.89929699897766 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 213.14943861961365 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 157.53304934501648 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 65.45526599884033 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 59.77876663208008 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 39.73486566543579 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n",
      "WARNING:twarc:rate limit exceeded: sleeping 10 secs\n"
     ]
    }
   ],
   "source": [
    "processed_tweet=open('IEEE dataset/PROCESSED DATA/'+file_+'.txt','w',encoding='utf8')\n",
    "for tweet in t.hydrate(open('IEEE dataset/TWEET IDS/'+file_+'.txt')):\n",
    "    txt=str(tweet['full_text'])\n",
    "    t_id=int(tweet['id'])\n",
    "    sent=d[t_id]\n",
    "    clean_txt=get_clean_data(txt)\n",
    "    if clean_txt!=\"\":\n",
    "        print((sent),end=\" \",file=processed_tweet)\n",
    "        print((clean_txt),file=processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweet.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweet=open('IEEE dataset/PROCESSED DATA/corona_tweets_01.txt','r',encoding='utf8')\n",
    "lines=processed_tweet.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319430"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
